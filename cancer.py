# -*- coding: utf-8 -*-
"""cancer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e210oT7KVOvgvjWMuRpmQiKiF8UOalos
"""

"""
Breast Cancer Classification with Logistic Regression

Predicts whether a breast tumor is malignant or benign using clinical measurements.
Evaluates a random baseline, trains logistic regression models, and studies the effect
of L1 regularization on accuracy and sparsity.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score


def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    """Displays a confusion matrix."""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure()
    plt.imshow(cm, cmap=plt.cm.Blues)
    plt.title(title)
    plt.xlabel("Predicted label")
    plt.ylabel("True label")
    plt.colorbar()

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, cm[i, j], ha="center", va="center")

    plt.show()


def run_baseline(y_train, y_test, random_state=2025):
    """Evaluates a random baseline classifier based on class prevalence."""
    p = np.mean(y_train)
    np.random.seed(random_state)
    y_pred = np.random.binomial(1, p, size=len(y_test))

    plot_confusion_matrix(y_test, y_pred, title="Baseline Confusion Matrix")

    print("Baseline Model Performance")
    print(f"Accuracy:  {accuracy_score(y_test, y_pred):.3f}")
    print(f"Precision: {precision_score(y_test, y_pred):.3f}")
    print(f"Recall:    {recall_score(y_test, y_pred):.3f}")
    print("-" * 40)


def train_logistic_regression(X_train, X_test, y_train, y_test):
    """Trains unregularized logistic regression with feature scaling."""
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = LogisticRegression(penalty=None, max_iter=10000, random_state=2025)
    model.fit(X_train_scaled, y_train)

    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    print("Logistic Regression Performance")
    print(f"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}")
    print(f"Test accuracy:     {accuracy_score(y_test, y_test_pred):.3f}")
    print("-" * 40)

    return X_train_scaled


def run_regularization_study(X_train_scaled, y_train):
    """Performs cross-validation study over L1 regularization strengths."""
    param_range = np.array([0.001, 0.01, 0.1, 1.0, 10.0, 100.0])
    val_scores = []
    sparsity_ratios = []

    for C in param_range:
        model = LogisticRegression(
            penalty="l1",
            solver="liblinear",
            C=C,
            tol=0.01,
            max_iter=10000,
            random_state=2025
        )
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring="accuracy")
        val_scores.append(cv_scores.mean())

        model.fit(X_train_scaled, y_train)
        coef = model.coef_.ravel()
        sparsity = np.mean(np.abs(coef) < 1e-4)
        sparsity_ratios.append(sparsity)

    plot_regularization_results(param_range, val_scores, sparsity_ratios)


def plot_regularization_results(param_range, val_scores, sparsity_ratios):
    """Plots validation curve and sparsity vs regularization strength."""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    ax1.semilogx(param_range, val_scores, marker="o")
    ax1.set_xlabel("C (Regularization strength)")
    ax1.set_ylabel("Cross-validation accuracy")
    ax1.set_title("Validation Curve")
    ax1.grid(True)

    ax2.semilogx(param_range, sparsity_ratios, marker="s", color="red")
    ax2.set_xlabel("C (Regularization strength)")
    ax2.set_ylabel("Sparsity ratio")
    ax2.set_title("Model Sparsity vs C")
    ax2.grid(True)

    plt.tight_layout()
    plt.show()

    print("C\t\tAccuracy\tSparsity")
    print("-" * 45)
    for i, C in enumerate(param_range):
        print(f"{C:>10.3f}\t{val_scores[i]:.3f}\t\t{sparsity_ratios[i]:.2f}")


def main():
    # Load dataset
    cancer = load_breast_cancer()
    X = cancer.data
    y = cancer.target

    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2025)

    print("Target classes:", cancer.target_names)
    print("Number of features:", X.shape[1])
    print("-" * 40)

    # Baseline evaluation
    run_baseline(y_train, y_test)

    # Logistic regression
    X_train_scaled = train_logistic_regression(X_train, X_test, y_train, y_test)

    # Regularization study
    run_regularization_study(X_train_scaled, y_train)


if __name__ == "__main__":
    main()